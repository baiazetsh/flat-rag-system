# ğŸ§  Migration RAG Assistant

A lightweight yet powerful **Retrieval-Augmented Generation (RAG)** system built with **FastAPI**, **Ollama**, and **Qdrant** â€” including a simple web interface for asking questions and viewing results.

---

## ğŸš€ Overview

This project connects a local language model with a vector database to build a working RAG pipeline.  
You can upload your text files, index them into Qdrant, and then ask natural-language questions.  
The system finds the most relevant chunks, builds a context, and lets the LLM generate the final answer.

---

## âœ¨ Features

- ğŸ” **Semantic Search** powered by Qdrant  
- ğŸ’¬ **Context-aware answers** using local LLMs (via Ollama)  
- ğŸ§© **Full RAG pipeline** â€” embeddings, retrieval, generation  
- ğŸ§± **FastAPI backend + HTML UI** (Jinja2 templates)  
- ğŸ“¦ **Docker-ready setup**  
- ğŸ§¾ **Document uploader** with automatic text chunking  

---

## âš™ï¸ Tech Stack

| Layer | Tool |
|-------|------|
| Backend | FastAPI |
| Vector DB | Qdrant |
| LLM Engine | Ollama |
| Data Models | Pydantic |
| Async HTTP | httpx |
| Frontend | Jinja2 Templates |
| Containers | Docker Compose |

---

## ğŸ“ Project Structure

## ğŸ–¼ï¸ Screenshots

### Main Interface
![Home UI](screenshots/ui_home.png)

### Example Answer
![Result UI](screenshots/ui_result.png)

[![Tests](https://github.com/<user>/<repo>/actions/workflows/tests.yml/badge.svg)](https://github.com/<user>/<repo>/actions/workflows/tests.yml)

